set -o errexit 
set -o pipefail
# setup environment
. set_environment.sh
# Argument handling
config=$1
checkpoint=$2
results_path=$3
HELP="\ntest.sh <config> <model_checkpoint> [<results_path>]\n"
[ -z "$config" ] && echo -e $HELP && exit 1
[ -z "$checkpoint" ] && echo -e $HELP && exit 1
[ -z "$results_path" ] && results_path=""
set -o nounset 

# Load config
. "$config"

# Default path
if [ "$results_path" == "" ];then
    # fix for ensembles
    single_checkpoint=$(echo $checkpoint | sed 's@\.pt:.*@@')
    results_path=$(dirname $single_checkpoint)/$TEST_TAG/test
fi
mkdir -p $(dirname $results_path)

echo 'CHECKPOINT '$checkpoint
echo 'OUTPUT IN > '$results_path

# to profile decoder
# decorate target function with @profile
# test_command="kernprof -o generate.lprof -l fairseq/generate.py"
# python -m line_profiler generate.py.lprof
test_command=fairseq-generate

# Decode to get predicted action sequence
if [ ! -f "${results_path}.actions" ];then
    echo "$test_command $FAIRSEQ_GENERATE_ARGS --path $checkpoint --results-path ${results_path}"
    $test_command $FAIRSEQ_GENERATE_ARGS \
        --path $checkpoint \
        --results-path ${results_path} 
fi


# FOR EACH TASK EVALUATE FOR EACH OF THE SUB TASKS INVOLVED e.g. AMR+NER
for single_task  in $(python -c "print(' '.join('$TASK_TAG'.split('+')))");do

      

    if [ "$single_task" == "dep-parsing" ];then
	python INOact2top.py ${results_path}.actions $ORACLE_FOLDER/test.en > ${results_path}.top

	

        python evaluate.py $ORACLE_FOLDER/gold_test.clean.tsv ${results_path}.top > ${results_path}.las

	python scripts/get_TOPtopdown_oracle.py ${results_path}.top > ${results_path}.actions2

	python scripts/TDact2top.py ${results_path}.actions2 $ORACLE_FOLDER/test.en > ${results_path}.top2

	python evaluate.py $ORACLE_FOLDER/gold_test.clean.tsv ${results_path}.top2 > ${results_path}.las2

        cat ${results_path}.las

	cat ${results_path}.las2

	
	
    else
 
        echo "Unsupported task $single_task"
        exit 1

    fi
 
done
